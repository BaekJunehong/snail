{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e90zKmPewaL2"
      },
      "source": [
        "# 환경 설정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umN-Qq9W3A1f"
      },
      "source": [
        "구글 드라이브와 Colab을 연동"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSqSE-DS297n",
        "outputId": "5f948ba1-202a-4a21-8730-7ef6a4978606"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnX1gx5vv_kc"
      },
      "source": [
        "\n",
        "Gpu 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KStnU69Dv-zz",
        "outputId": "775ffc19-a441-4226-ddde-30ca1e12d0d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-fd43b2a4-08a6-9017-fb68-9ee5be5b2c86)\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnDQzwwLwC-c"
      },
      "source": [
        "whisper ai 사용에 필요한 python 패키지"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86z0bIqxeMki",
        "outputId": "8e958426-4891-4796-9eae-b2b1a0023ad1"
      },
      "outputs": [],
      "source": [
        "# 데이터셋과 transformers 설치\n",
        "!pip install datasets>=2.6.1\n",
        "!pip install git+https://github.com/huggingface/transformers\n",
        "\n",
        "# 오디오 처리를 위한 librosa 설치\n",
        "!pip install librosa\n",
        "\n",
        "# 성능 측정을 위한 evaluate와 jiwer 설치\n",
        "!pip install evaluate>=0.30\n",
        "!pip install jiwer\n",
        "\n",
        "# 인터랙티브 인터페이스를 위한 gradio 설치\n",
        "!pip install gradio\n",
        "\n",
        "# Transformers와 PyTorch를 함께 사용하기 위한 accelerate 설치\n",
        "!pip install transformers[torch]\n",
        "!pip install accelerate>=0.20.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LV65OMc_wGrJ"
      },
      "source": [
        "modules 과 packges import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcHXA33leT0A"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, List, Union\n",
        "import torch\n",
        "\n",
        "# import the relavant libraries for loggin in\n",
        "from huggingface_hub import HfApi, HfFolder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTo-ygLdwTwp"
      },
      "source": [
        "# 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcErvqAgefKS"
      },
      "outputs": [],
      "source": [
        "def login_hugging_face(token):\n",
        "    \"\"\"\n",
        "    Hugging Face API 토큰을 사용하여 Hugging Face에 로그인합니다.\n",
        "    \"\"\"\n",
        "    folder = HfFolder()\n",
        "    folder.save_token(token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_jIKSBAtTEo"
      },
      "source": [
        "모델에 입력으로 사용될 데이터와 라벨 데이터가 준비"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "povAUjkcejQU"
      },
      "outputs": [],
      "source": [
        "def prepare_dataset(batch):\n",
        "    \"\"\"\n",
        "    Whisper AI 모델에 적합한 형식으로 오디오 데이터를 준비합니다.\n",
        "    \"\"\"\n",
        "    # 오디오 데이터를 48kHz에서 16kHz로 변환하여 로드\n",
        "    audio = batch[\"audio\"]\n",
        "\n",
        "    # 입력 오디오 배열로부터 log-Mel 입력 특성을 계산\n",
        "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
        "\n",
        "    # 대상 텍스트를 토큰화하고 라벨 ID로 인코딩\n",
        "    batch[\"labels\"] = tokenizer(batch[\"sentence\"]).input_ids\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHs-HkuJtbXe"
      },
      "source": [
        "데이터 콜레이터 클래스는 ASR 모델의 훈련 및 평가 과정에서 데이터의 전처리와 패딩을 처리하는 역할을 수행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQEmML4Zex5z"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class DataCollatorSpeechSeq2SeqWithPadding:\n",
        "    \"\"\"\n",
        "    Use Data Collator to perform Speech Seq2Seq with padding\n",
        "    \"\"\"\n",
        "    processor: Any\n",
        "\n",
        "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
        "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
        "        # first treat the audio inputs by simply returning torch tensors\n",
        "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
        "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
        "\n",
        "        # get the tokenized label sequences\n",
        "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
        "        # pad the labels to max length\n",
        "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
        "\n",
        "        # replace padding with -100 to ignore loss correctly\n",
        "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
        "\n",
        "        # if bos token is appended in previous tokenization step,\n",
        "        # cut bos token here as it's append later anyways\n",
        "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
        "            labels = labels[:, 1:]\n",
        "\n",
        "        batch[\"labels\"] = labels\n",
        "\n",
        "        return batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_qwfaqUvf4w"
      },
      "source": [
        "평기지표: CER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mg9QFaBGe2nj"
      },
      "outputs": [],
      "source": [
        "from jiwer import wer\n",
        "\n",
        "def compute_cer(pred):\n",
        "    pred_ids = pred.predictions\n",
        "    label_ids = pred.label_ids\n",
        "\n",
        "    # replace -100 with the pad_token_id\n",
        "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
        "\n",
        "    # we do not want to group tokens when computing the metrics\n",
        "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
        "\n",
        "    cer = wer(label_str, pred_str)\n",
        "\n",
        "    return {\"cer\": cer}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YT9LBBXdwIsi"
      },
      "source": [
        "# STEP 0. Hugging Face 로그인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywDnKqWTe5Hu",
        "outputId": "68f76282-1ff3-4be4-e8e6-6215cab75155"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "We are logged in to Hugging Face now!\n"
          ]
        }
      ],
      "source": [
        "# get your account token from https://huggingface.co/settings/tokens\n",
        "token = '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'\n",
        "login_hugging_face(token)\n",
        "print('We are logged in to Hugging Face now!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qatnD5H2waD8"
      },
      "source": [
        "# STEP 1. 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rxOZH0NiZ3q",
        "outputId": "0a893615-6069-49e7-ce11-dd8f68f97e0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Audio Files:\n",
            "K00017778-BMG20-L1N2D4-E-K0KK-04055750.wav\n",
            "K00017747-BMG20-L1N2D1-E-K0KK-04126990.wav\n",
            "K00017759-BMG30-L1N2D4-E-K0KK-04648172.wav\n",
            "\n",
            "Label Files:\n",
            "K00017748-BMG32-L1N2D1-E-K0KK-04610688.txt\n",
            "K000110597-BFG20-L1N2D2-E-K0KK-05001078.txt\n",
            "K00017750-BFG32-L1N2D1-E-K0KK-04062324.txt\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "def extract_zip_files(zip_file_path, extracted_folder_path):\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extracted_folder_path)\n",
        "\n",
        "def change_folder_structure(extracted_folder_path):\n",
        "    audio_target_dir = os.path.join(extracted_folder_path, \"audio\")\n",
        "    label_target_dir = os.path.join(extracted_folder_path, \"labels\")\n",
        "\n",
        "    # 폴더 생성\n",
        "    os.makedirs(audio_target_dir, exist_ok=True)\n",
        "    os.makedirs(label_target_dir, exist_ok=True)\n",
        "\n",
        "    for root, _, files in os.walk(extracted_folder_path):\n",
        "        for file in files:\n",
        "            if file.endswith(\".wav\"):\n",
        "                audio_file_path = os.path.join(root, file)\n",
        "                new_audio_file_path = os.path.join(audio_target_dir, file)\n",
        "                shutil.move(audio_file_path, new_audio_file_path)\n",
        "\n",
        "            elif file.endswith(\".json\"):\n",
        "                label_file_path = os.path.join(root, file)\n",
        "                audio_id = file.split(\".\")[0]\n",
        "                new_label_file_path = os.path.join(label_target_dir, f\"{audio_id}.txt\")\n",
        "                shutil.move(label_file_path, new_label_file_path)\n",
        "\n",
        "    # 빈 폴더 제거 (오직 audio_target_dir와 label_target_dir만 남아있을 것)\n",
        "    for root, dirs, _ in os.walk(extracted_folder_path, topdown=False):\n",
        "        for dir in dirs:\n",
        "            if dir not in [os.path.basename(audio_target_dir), os.path.basename(label_target_dir)]:\n",
        "                dir_path = os.path.join(root, dir)\n",
        "                os.rmdir(dir_path)\n",
        "\n",
        "# 2. 데이터 파일이 저장된 경로를 지정합니다.\n",
        "zip_file_path_audio = '/content/drive/MyDrive/data_file/sample_15000_ko_child/audio_sample.zip'\n",
        "zip_file_path_label = '/content/drive/MyDrive/data_file/sample_15000_ko_child/label_sample.zip'\n",
        "extracted_folder_path = '/content/data/'  # 압축 해제된 데이터가 저장될 폴더 경로\n",
        "\n",
        "# 폴더 초기화\n",
        "if os.path.exists(extracted_folder_path):\n",
        "    shutil.rmtree(extracted_folder_path)\n",
        "\n",
        "# 3. zip 파일을 압축 해제합니다.\n",
        "extract_zip_files(zip_file_path_audio, extracted_folder_path)\n",
        "extract_zip_files(zip_file_path_label, extracted_folder_path)\n",
        "\n",
        "# 4. 폴더 구조 변경\n",
        "change_folder_structure(extracted_folder_path)\n",
        "\n",
        "# 5. 구조 확인\n",
        "# 데이터 폴더 경로 설정\n",
        "data_folder = '/content/data/'\n",
        "\n",
        "# audio 폴더 내 파일 목록 확인\n",
        "audio_files = os.listdir(os.path.join(data_folder, 'audio'))\n",
        "print(\"Audio Files:\")\n",
        "for i in range(3):  # 최대 3개 파일만 출력\n",
        "    if i < len(audio_files):\n",
        "        print(audio_files[i])\n",
        "\n",
        "# labels 폴더 내 파일 목록 확인\n",
        "label_files = os.listdir(os.path.join(data_folder, 'labels'))\n",
        "print(\"\\nLabel Files:\")\n",
        "for i in range(3):  # 최대 3개 파일만 출력\n",
        "    if i < len(label_files):\n",
        "        print(label_files[i])\n",
        "\n",
        "# 이제 \"/content/data/\" 폴더 내에 \"audio\" 폴더와 \"labels\" 폴더가 생성되며,\n",
        "# 해당 폴더에 원천데이터인 wav 파일과 라벨링데이터인 txt 파일이 저장됩니다.\n",
        "# 이후에는 해당 경로에서 데이터를 불러와서 학습을 진행하시면 됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7WR1Atowdo5"
      },
      "source": [
        "audio data 개수와 label data 개수 같은지 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jVpPltDlYAL",
        "outputId": "e8a311c7-4399-4855-e9bb-b1f26c643be2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "오디오 파일 개수: 15953\n",
            "JSON 파일 개수: 15953\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "data_folder = \"/content/data\"\n",
        "audio_folder = os.path.join(data_folder, \"audio\")\n",
        "label_folder = os.path.join(data_folder, \"labels\")\n",
        "\n",
        "# audio 폴더 내의 파일 개수 확인\n",
        "audio_files = [file for file in os.listdir(audio_folder) if file.endswith(\".wav\")]\n",
        "print(f\"오디오 파일 개수: {len(audio_files)}\")\n",
        "\n",
        "# labels 폴더 내의 파일 개수 확인\n",
        "label_files = [file for file in os.listdir(label_folder) if file.endswith(\".txt\")]\n",
        "print(f\"JSON 파일 개수: {len(label_files)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNbgGyYjwm6P"
      },
      "source": [
        "train과 test 데이터로 나누기 및 모델 학습을 위한 구조 변경"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNqAcayci4BN",
        "outputId": "3c8a03c8-dcf2-4a9c-8bf5-87aefec49b04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['audio', 'sentence'],\n",
            "        num_rows: 14357\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['audio', 'sentence'],\n",
            "        num_rows: 1596\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "from datasets import DatasetDict, Dataset, load_dataset\n",
        "import os\n",
        "import random\n",
        "import json\n",
        "\n",
        "def create_dataset(data_folder):\n",
        "    audio_folder = os.path.join(data_folder, \"audio\")\n",
        "    label_folder = os.path.join(data_folder, \"labels\")\n",
        "\n",
        "    # audio 폴더 내의 WAV 파일 리스트를 가져옴\n",
        "    audio_files = [file for file in os.listdir(audio_folder) if file.endswith(\".wav\")]\n",
        "\n",
        "    # label 폴더 내의 JSON 파일 리스트를 가져옴\n",
        "    label_files = [file for file in os.listdir(label_folder) if file.endswith(\".txt\")]\n",
        "\n",
        "    # WAV 파일과 JSON 파일이 정상적으로 매칭되어야 함\n",
        "    assert len(audio_files) == len(label_files)\n",
        "\n",
        "    # 데이터셋 생성\n",
        "    dataset_dict = DatasetDict()\n",
        "    train_data = {\"audio\": [], \"sentence\": []}\n",
        "    test_data = {\"audio\": [], \"sentence\": []}\n",
        "\n",
        "    # 데이터를 무작위로 섞어서 train과 test로 나누기\n",
        "    data_pairs = list(zip(audio_files, label_files))\n",
        "    random.shuffle(data_pairs)\n",
        "\n",
        "    train_size = int(len(data_pairs) * 0.9)\n",
        "\n",
        "    for audio_file, label_file in data_pairs[:train_size]:\n",
        "        # WAV 파일과 JSON 파일을 읽어서 train 데이터셋에 추가\n",
        "        audio_path = os.path.join(audio_folder, audio_file)\n",
        "        label_path = os.path.join(label_folder, label_file)\n",
        "\n",
        "        with open(label_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            label_data = json.load(f)\n",
        "            sentence = label_data[\"Transcription\"][\"LabelText\"]\n",
        "\n",
        "        train_data[\"audio\"].append(audio_path)\n",
        "        train_data[\"sentence\"].append(sentence)\n",
        "\n",
        "    for audio_file, label_file in data_pairs[train_size:]:\n",
        "        # WAV 파일과 JSON 파일을 읽어서 test 데이터셋에 추가\n",
        "        audio_path = os.path.join(audio_folder, audio_file)\n",
        "        label_path = os.path.join(label_folder, label_file)\n",
        "\n",
        "        with open(label_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            label_data = json.load(f)\n",
        "            sentence = label_data[\"Transcription\"][\"LabelText\"]\n",
        "\n",
        "        test_data[\"audio\"].append(audio_path)\n",
        "        test_data[\"sentence\"].append(sentence)\n",
        "\n",
        "    # 데이터셋에 추가\n",
        "    dataset_dict[\"train\"] = Dataset.from_dict(train_data)\n",
        "    dataset_dict[\"test\"] = Dataset.from_dict(test_data)\n",
        "\n",
        "    return dataset_dict\n",
        "\n",
        "# 데이터 폴더 경로 지정\n",
        "data_folder = \"/content/data\"\n",
        "\n",
        "# 데이터셋 생성\n",
        "custom_dataset = create_dataset(data_folder)\n",
        "\n",
        "# \"sentence\" 필드만 출력\n",
        "print(custom_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bphs7qjGwqov"
      },
      "source": [
        "audio data 와 text data 일부 출력"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5YEK2-Yl2jr",
        "outputId": "a40043b2-7799-423c-e6ef-93debe0331fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "오디오 데이터 일부 출력:\n",
            "/content/data/audio/K00017743-BFG33-L1N2D1-E-K0KK-04309628.wav\n",
            "\n",
            "텍스트 문장 데이터 일부 출력:\n",
            "그런데 우리가 도착한 바다는 파도가 엄청 높았어요.\n"
          ]
        }
      ],
      "source": [
        "# 오디오 데이터 일부 출력\n",
        "print(\"오디오 데이터 일부 출력:\")\n",
        "print(custom_dataset[\"train\"][\"audio\"][2])\n",
        "print()\n",
        "\n",
        "# 텍스트 문장 데이터 일부 출력\n",
        "print(\"텍스트 문장 데이터 일부 출력:\")\n",
        "print(custom_dataset[\"train\"][\"sentence\"][2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYXaMpOtw6Lm"
      },
      "source": [
        "# STEP 2. Feature Extractor, Tokenizer and Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ljILt1DpwcJ"
      },
      "outputs": [],
      "source": [
        "from transformers import WhisperFeatureExtractor\n",
        "from transformers import WhisperTokenizer\n",
        "\n",
        "# - Load Feature extractor: WhisperFeatureExtractor\n",
        "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-small\")\n",
        "\n",
        "# - Load Tokenizer: WhisperTokenizer\n",
        "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\", language=\"korean\", task=\"transcribe\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRlUZ0PmxAEL"
      },
      "source": [
        "# STEP 3. Combine elements with WhisperProcessor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clpQzKlqpzq3"
      },
      "outputs": [],
      "source": [
        "from transformers import WhisperProcessor\n",
        "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"korean\", task=\"transcribe\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzx2yMdDxVJv"
      },
      "source": [
        "# STEP 4. 데이터 준비"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269,
          "referenced_widgets": [
            "f2a416f71e3a4c578ddaae4cde33bc87",
            "06bfe2ed2e5c423dbd1a86e6d7ea0b55",
            "3643e5d7b88a4dc5a35eaeb66aa7e868",
            "b7898c85c5444189b325bf81dbed3e91",
            "09836aceceb34a9c8a69da9d34fbfd35",
            "04a876a106e945d49f13a17ccf10ea3b",
            "6aff3220d2fd44c6ad223fcd05dc7525",
            "59905bd8e71e4e49802ca280c77e54e4",
            "06cbbf56c9d046b6a6a2b8465beda74f",
            "05cf55ff8ff54ee1bca0040295cdee73",
            "85bb91c1a8da43cfb53e64aa80fc72a4",
            "6fb34229cf284184869eff7e114c8c2e",
            "732808fa4e484947a20e4d3ab71a5dc0",
            "35e2f42d9b304d7aad30dc0c723d67f8",
            "c02fd58520ba4ce8a857697db85d49be",
            "999d4eb132ed42fe90f15dc7014c9e31",
            "0911b505dde948818f377e3de11e80c6",
            "f4645c7426774d0885e339f9ce1ba2aa",
            "c28bfbce2b134e18a3a5a934d2514456",
            "e2f1287da2ee477cb3cc24974d5261a7",
            "1697879c105b414c9d631a700eef1173",
            "3bb29f4ea15a4800962606017fd8e414"
          ]
        },
        "id": "luZjHLr2p2PU",
        "outputId": "d73acb91-03b3-4939-821b-d8f9e14fdf62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| Check the audio example\n",
            "{'audio': '/content/data/audio/K00017844-BMG33-L1N2D1-E-K0KK-04039796.wav', 'sentence': '전을 부치다 보면 뜨거운 기름이 팔,다리에 사정없이 튀어 위험하다'}\n",
            "\n",
            "| Check the effect of downsampling:\n",
            "{'audio': {'path': '/content/data/audio/K00017844-BMG33-L1N2D1-E-K0KK-04039796.wav', 'array': array([0., 0., 0., ..., 0., 0., 0.]), 'sampling_rate': 16000}, 'sentence': '전을 부치다 보면 뜨거운 기름이 팔,다리에 사정없이 튀어 위험하다'}\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f2a416f71e3a4c578ddaae4cde33bc87",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/14357 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6fb34229cf284184869eff7e114c8c2e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1596 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print('| Check the audio example')\n",
        "print(f'{custom_dataset[\"train\"][0]}\\n')\n",
        "\n",
        "# Downsample from 48kHZ to 16kHZ\n",
        "# Whisper AI 모델이 16kHz의 샘플링 속도에서 훈련되어서\n",
        "# 입력 데이터를 16kHz로 다운샘플링하는 것이 필요\n",
        "from datasets import Audio\n",
        "custom_dataset = custom_dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
        "\n",
        "print('| Check the effect of downsampling:')\n",
        "print(f'{custom_dataset[\"train\"][0]}\\n')\n",
        "\n",
        "# Prepare and use function to prepare our data ready for the Whisper AI model\n",
        "custom_dataset = custom_dataset.map(\n",
        "    prepare_dataset,\n",
        "    remove_columns=custom_dataset.column_names[\"train\"],\n",
        "    num_proc=1 # num_proc > 1 will enable multiprocessing / num_proc = 2 -> 1로 변경함\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRFES7w9xava"
      },
      "source": [
        "# STEP 5. Training and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceB98ofDqR2u"
      },
      "outputs": [],
      "source": [
        "# STEP 5.1. Initialize the Data collator\n",
        "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n",
        "\n",
        "# STEP 5.1. Define evaluation metric\n",
        "import evaluate\n",
        "metric = evaluate.load(\"cer\")\n",
        "\n",
        "# STEP 5.3. Load a pre-trained Checkpoint\n",
        "from transformers import WhisperForConditionalGeneration\n",
        "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
        "\n",
        "\"\"\"\n",
        "Overide generation arguments:\n",
        "- no tokens are forced as decoder outputs: https://huggingface.co/docs/transformers/main_classes/text_generation#transformers.generation_utils.GenerationMixin.generate.forced_decoder_ids\n",
        "- no tokens are suppressed during generation: https://huggingface.co/docs/transformers/main_classes/text_generation#transformers.generation_utils.GenerationMixin.generate.suppress_tokens\n",
        "\"\"\"\n",
        "model.config.forced_decoder_ids = None\n",
        "model.config.suppress_tokens = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        },
        "id": "9gGTa9HVqXov",
        "outputId": "c2f1bcf0-328c-4e50-f599-c5dd016270a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training 시작\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache = True` is incompatible with gradient checkpointing. Setting `use_cache = False`...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='451' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [451/500 4:20:15 < 28:24, 0.03 it/s, Epoch 0.50/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Cer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>5.605800</td>\n",
              "      <td>4.006696</td>\n",
              "      <td>1.471352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>3.580100</td>\n",
              "      <td>3.273457</td>\n",
              "      <td>1.076722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>3.075600</td>\n",
              "      <td>2.935802</td>\n",
              "      <td>1.193714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>2.950700</td>\n",
              "      <td>2.854623</td>\n",
              "      <td>1.245989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>2.881400</td>\n",
              "      <td>2.820464</td>\n",
              "      <td>2.125177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>2.811400</td>\n",
              "      <td>2.787316</td>\n",
              "      <td>1.939321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>2.767900</td>\n",
              "      <td>2.765740</td>\n",
              "      <td>1.962894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>2.762300</td>\n",
              "      <td>2.749339</td>\n",
              "      <td>1.340172</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='137' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [137/200 16:35 < 07:41, 0.14 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [500/500 5:17:10, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Cer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>5.605800</td>\n",
              "      <td>4.006696</td>\n",
              "      <td>1.471352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>3.580100</td>\n",
              "      <td>3.273457</td>\n",
              "      <td>1.076722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>3.075600</td>\n",
              "      <td>2.935802</td>\n",
              "      <td>1.193714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>2.950700</td>\n",
              "      <td>2.854623</td>\n",
              "      <td>1.245989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>2.881400</td>\n",
              "      <td>2.820464</td>\n",
              "      <td>2.125177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>2.811400</td>\n",
              "      <td>2.787316</td>\n",
              "      <td>1.939321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>2.767900</td>\n",
              "      <td>2.765740</td>\n",
              "      <td>1.962894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>2.762300</td>\n",
              "      <td>2.749339</td>\n",
              "      <td>1.340172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>2.708200</td>\n",
              "      <td>2.742016</td>\n",
              "      <td>1.189458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>2.727000</td>\n",
              "      <td>2.736261</td>\n",
              "      <td>1.105315</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training 완료\n"
          ]
        }
      ],
      "source": [
        "# STEP 5.4. Define the training configuration\n",
        "\"\"\"\n",
        "Check for Seq2SeqTrainingArguments here:\n",
        "https://huggingface.co/docs/transformers/main_classes/trainer#transformers.Seq2SeqTrainingArguments\n",
        "\"\"\"\n",
        "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./whisper-small-0812\",  # 저장된 모델 및 결과물의 디렉토리 경로\n",
        "    per_device_train_batch_size=16,  # 한 번에 처리되는 훈련 배치 크기\n",
        "    gradient_accumulation_steps=1,  # 배치 크기 감소시 그래디언트 누적을 통한 학습 안정화\n",
        "    learning_rate=1e-5,  # 학습률\n",
        "    warmup_steps=100,  # 초기 학습률 조정을 위한 웜업 스텝 수 / 일반적으로는 10% ~ 20%의 전체 학습 스텝 수에 해당하는 값을 시도\n",
        "    max_steps=500,  # 전체 훈련 스텝 수\n",
        "    gradient_checkpointing=True,  # 그래디언트 체크포인팅을 통한 메모리 절약\n",
        "    fp16=True,  # FP16 형식으로 훈련 수행 (반정밀도 부동소수점)( cpu 가동시 안씀)\n",
        "    evaluation_strategy=\"steps\",  # 검증 수행 전략 설정\n",
        "    per_device_eval_batch_size=8,  # 한 번에 처리되는 검증 배치 크기\n",
        "    predict_with_generate=True,  # 생성된 토큰을 통해 예측 수행\n",
        "    generation_max_length=225,  # 생성된 토큰의 최대 길이 (225 )\n",
        "    eval_steps=50,  # 검증 수행 스텝 수\n",
        "    logging_steps=50,  # 로그 기록 스텝 수\n",
        "    load_best_model_at_end=False,  # 훈련 종료 시 최적 모델 로드 여부\n",
        "    metric_for_best_model=\"cer\",  # 최적 모델 선정을 위한 평가 지표 wer -> cer로 변경\n",
        "    greater_is_better=False,  # 평가 지표 값이 높을수록 좋은지 여부\n",
        "    save_steps=50  # 변경된 save_steps 값\n",
        ")\n",
        "\n",
        "# Initialize a trainer.\n",
        "\"\"\"\n",
        "Hugging Face trainer에 다음의 값을 전달\n",
        "training arguments, model, dataset, data collator and compute_metrics function.\n",
        "\"\"\"\n",
        "# 지정된 인자 및 구성요소로 Initialize a trainer.\n",
        "trainer = Seq2SeqTrainer(\n",
        "    args=training_args,                   # 이전에 정의한 훈련 인자\n",
        "    model=model,                          # 훈련할 ASR 모델\n",
        "    train_dataset=custom_dataset[\"train\"],# 훈련 데이터셋\n",
        "    eval_dataset=custom_dataset[\"test\"],  # 평가 데이터셋\n",
        "    data_collator=data_collator,           # 데이터 전처리를 위한 데이터 콜레이터\n",
        "    compute_metrics=compute_cer,          # CER 메트릭을 계산하는 함수\n",
        "    tokenizer=processor.feature_extractor, # 입력 오디오 데이터를 처리하기 위한 토크나이저\n",
        ")\n",
        "\n",
        "# training 시작전에 processor object 저장\n",
        "processor.save_pretrained(training_args.output_dir)\n",
        "\n",
        "# STEP 5.5. Training\n",
        "\"\"\"\n",
        "Training will take appr. 5-10 hours depending on your GPU.\n",
        "\"\"\"\n",
        "print('Training 시작')\n",
        "trainer.train()  # <-- training 시작\n",
        "print('Training 완료')\n",
        "\n",
        "#\"Step\": 모델의 훈련 과정에서 진행되는 각 스텝을 나타내는 숫자입니다.\n",
        "#스텝은 주로 배치(batch) 단위로 모델이 업데이트되는 지점을 의미합니다.\n",
        "\n",
        "# \"Training Loss\": 훈련 데이터를 사용하여 모델을 학습할 때 나타나는 손실 값입니다.\n",
        "#이 값은 모델이 예측한 결과와 실제 정답과의 차이를 나타냅니다.\n",
        "\n",
        "# \"Validation Loss\": 훈련 중에 일정 주기마다 검증 데이터를 사용하여 모델의 성능을\n",
        "# 평가한 후 나타나는 손실 값입니다.\n",
        "# 이 값도 마찬가지로 모델의 예측 결과와 실제 정답과의 차이를 나타냅니다.\n",
        "# 검증 손실이 감소하는 것은 모델이 일반화되는 표시입니다.\n",
        "\n",
        "# \"CER\" (Character Error Rate): 훈련 중에 일정 주기마다 검증 데이터를 사용하여\n",
        "#모델의 문자 에러 비율(CER)을 평가한 값입니다.\n",
        "#CER은 텍스트 분야에서 자주 사용되는 평가 지표 중 하나로,\n",
        "#모델이 생성한 텍스트와 실제 텍스트 사이의 문자 수준 오류 비율을 나타냅니다.\n",
        "#CER이 낮을수록 모델의 성능이 좋다고 판단됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ic1yCT8HuUI8"
      },
      "source": [
        "학습된 모델 평가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "GPMYJbdee4QU",
        "outputId": "f6fa88d6-c1c5-424f-b5f6-9cf226773743"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='15' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 15/200 01:43 < 22:44, 0.14 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [200/200 24:14]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 2.7362608909606934,\n",
              " 'eval_cer': 1.105314853214013,\n",
              " 'eval_runtime': 1549.5567,\n",
              " 'eval_samples_per_second': 1.03,\n",
              " 'eval_steps_per_second': 0.129,\n",
              " 'epoch': 0.56}"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGxBKiX1EQVC"
      },
      "source": [
        "학습된 모델 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "liHO1-IIEP4O"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(\"/content/drive/MyDrive/model/whisper_small_0812_ver1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vg2zOyXUx4ND"
      },
      "source": [
        "모델에 토크나이저 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wiaehlroqf-r",
        "outputId": "f3aae0d6-c809-4b75-c4d1-878963a13dd3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/model/whisper_small_0812_ver1/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/model/whisper_small_0812_ver1/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/model/whisper_small_0812_ver1/vocab.json',\n",
              " '/content/drive/MyDrive/model/whisper_small_0812_ver1/merges.txt',\n",
              " '/content/drive/MyDrive/model/whisper_small_0812_ver1/normalizer.json',\n",
              " '/content/drive/MyDrive/model/whisper_small_0812_ver1/added_tokens.json',\n",
              " '/content/drive/MyDrive/model/whisper_small_0812_ver1/tokenizer.json')"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Load the trained tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/whisper-small-0812\")\n",
        "\n",
        "# Specify the directory where you want to save the tokenizer\n",
        "save_directory = \"/content/drive/MyDrive/model/whisper_small_0812_ver1\"\n",
        "\n",
        "# Save the tokenizer to the specified directory\n",
        "tokenizer.save_pretrained(save_directory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4Ucc7_ZuaHa"
      },
      "source": [
        "모델 파일내용 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTNvGXJ4uamH",
        "outputId": "ff6ddc3c-1c02-45b0-83b7-2944aa493f3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['config.json', 'generation_config.json', 'pytorch_model.bin', 'preprocessor_config.json', 'training_args.bin', 'tokenizer_config.json', 'special_tokens_map.json', 'added_tokens.json', 'vocab.json', 'merges.txt', 'normalizer.json', 'tokenizer.json']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "model_path = \"/content/drive/MyDrive/model/whisper_small_0812_ver1\"\n",
        "files_in_model_path = os.listdir(model_path)\n",
        "print(files_in_model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAvxlHpuDdGP"
      },
      "source": [
        "# STEP 6. Model use"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtMD0NWiucha"
      },
      "source": [
        "모델 실행코드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GtKF4UOueAc",
        "outputId": "7bb48ba1-9d8a-47d8-aa70-c412d4c04833"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1254: UserWarning: Using the model-agnostic default `max_length` (=448) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1254: UserWarning: Using the model-agnostic default `max_length` (=448) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1254: UserWarning: Using the model-agnostic default `max_length` (=448) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "model_name_or_path = \"/content/drive/MyDrive/model/whisper_small_0812_ver1\"\n",
        "asr = pipeline(model=model_name_or_path, task=\"automatic-speech-recognition\")\n",
        "\n",
        "def transcribe_audio(audio_path):\n",
        "    transcription = asr(audio_path)\n",
        "    return transcription['text']  # Use 'text' key to get the transcribed text\n",
        "\n",
        "audio_file_paths = [\n",
        "    \"/content/drive/MyDrive/data_file/테스트 음원/K00013596-BMG23-L1N2D1-E-K0KK-02164576.wav\",\n",
        "    \"/content/drive/MyDrive/data_file/테스트 음원/K00013596-BMG23-L1N2D1-E-K0KK-02164794.wav\",\n",
        "    \"/content/drive/MyDrive/data_file/테스트 음원/K00013596-BMG23-L1N2D1-E-K0KK-02165323.wav\"\n",
        "    # 추가 음성 파일 경로\n",
        "]\n",
        "\n",
        "for audio_file_path in audio_file_paths:\n",
        "    transcription_text = transcribe_audio(audio_file_path)\n",
        "    print(transcription_text)\n",
        "    print(\"=\" * 50)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "e90zKmPewaL2",
        "WTo-ygLdwTwp",
        "YT9LBBXdwIsi",
        "qatnD5H2waD8"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "04a876a106e945d49f13a17ccf10ea3b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05cf55ff8ff54ee1bca0040295cdee73": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06bfe2ed2e5c423dbd1a86e6d7ea0b55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04a876a106e945d49f13a17ccf10ea3b",
            "placeholder": "​",
            "style": "IPY_MODEL_6aff3220d2fd44c6ad223fcd05dc7525",
            "value": "Map: 100%"
          }
        },
        "06cbbf56c9d046b6a6a2b8465beda74f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0911b505dde948818f377e3de11e80c6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09836aceceb34a9c8a69da9d34fbfd35": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1697879c105b414c9d631a700eef1173": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35e2f42d9b304d7aad30dc0c723d67f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c28bfbce2b134e18a3a5a934d2514456",
            "max": 1596,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e2f1287da2ee477cb3cc24974d5261a7",
            "value": 1596
          }
        },
        "3643e5d7b88a4dc5a35eaeb66aa7e868": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59905bd8e71e4e49802ca280c77e54e4",
            "max": 14357,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06cbbf56c9d046b6a6a2b8465beda74f",
            "value": 14357
          }
        },
        "3bb29f4ea15a4800962606017fd8e414": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59905bd8e71e4e49802ca280c77e54e4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6aff3220d2fd44c6ad223fcd05dc7525": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6fb34229cf284184869eff7e114c8c2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_732808fa4e484947a20e4d3ab71a5dc0",
              "IPY_MODEL_35e2f42d9b304d7aad30dc0c723d67f8",
              "IPY_MODEL_c02fd58520ba4ce8a857697db85d49be"
            ],
            "layout": "IPY_MODEL_999d4eb132ed42fe90f15dc7014c9e31"
          }
        },
        "732808fa4e484947a20e4d3ab71a5dc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0911b505dde948818f377e3de11e80c6",
            "placeholder": "​",
            "style": "IPY_MODEL_f4645c7426774d0885e339f9ce1ba2aa",
            "value": "Map: 100%"
          }
        },
        "85bb91c1a8da43cfb53e64aa80fc72a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "999d4eb132ed42fe90f15dc7014c9e31": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7898c85c5444189b325bf81dbed3e91": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05cf55ff8ff54ee1bca0040295cdee73",
            "placeholder": "​",
            "style": "IPY_MODEL_85bb91c1a8da43cfb53e64aa80fc72a4",
            "value": " 14357/14357 [21:44&lt;00:00, 12.86 examples/s]"
          }
        },
        "c02fd58520ba4ce8a857697db85d49be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1697879c105b414c9d631a700eef1173",
            "placeholder": "​",
            "style": "IPY_MODEL_3bb29f4ea15a4800962606017fd8e414",
            "value": " 1596/1596 [02:28&lt;00:00, 11.17 examples/s]"
          }
        },
        "c28bfbce2b134e18a3a5a934d2514456": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2f1287da2ee477cb3cc24974d5261a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f2a416f71e3a4c578ddaae4cde33bc87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_06bfe2ed2e5c423dbd1a86e6d7ea0b55",
              "IPY_MODEL_3643e5d7b88a4dc5a35eaeb66aa7e868",
              "IPY_MODEL_b7898c85c5444189b325bf81dbed3e91"
            ],
            "layout": "IPY_MODEL_09836aceceb34a9c8a69da9d34fbfd35"
          }
        },
        "f4645c7426774d0885e339f9ce1ba2aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
