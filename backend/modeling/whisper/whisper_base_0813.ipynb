{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e90zKmPewaL2"
      },
      "source": [
        "# í™˜ê²½ ì„¤ì •"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umN-Qq9W3A1f"
      },
      "source": [
        "êµ¬ê¸€ ë“œë¼ì´ë¸Œì™€ Colabì„ ì—°ë™"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSqSE-DS297n",
        "outputId": "03645347-e76a-420b-90e4-65385e3e3926"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnX1gx5vv_kc"
      },
      "source": [
        "\n",
        "Gpu í™•ì¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KStnU69Dv-zz",
        "outputId": "3b792fb4-b067-4fff-9f1e-edaee7e965f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-97c1190d-3290-cdc8-3530-34e6502c8b65)\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnDQzwwLwC-c"
      },
      "source": [
        "whisper ai ì‚¬ìš©ì— í•„ìš”í•œ python íŒ¨í‚¤ì§€"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86z0bIqxeMki"
      },
      "outputs": [],
      "source": [
        "# ë°ì´í„°ì…‹ê³¼ transformers ì„¤ì¹˜\n",
        "!pip install datasets>=2.6.1\n",
        "!pip install git+https://github.com/huggingface/transformers\n",
        "\n",
        "# ì˜¤ë””ì˜¤ ì²˜ë¦¬ë¥¼ ìœ„í•œ librosa ì„¤ì¹˜\n",
        "!pip install librosa\n",
        "\n",
        "# ì„±ëŠ¥ ì¸¡ì •ì„ ìœ„í•œ evaluateì™€ jiwer ì„¤ì¹˜\n",
        "!pip install evaluate>=0.30\n",
        "!pip install jiwer\n",
        "\n",
        "# ì¸í„°ë™í‹°ë¸Œ ì¸í„°í˜ì´ìŠ¤ë¥¼ ìœ„í•œ gradio ì„¤ì¹˜\n",
        "!pip install gradio\n",
        "\n",
        "# Transformersì™€ PyTorchë¥¼ í•¨ê»˜ ì‚¬ìš©í•˜ê¸° ìœ„í•œ accelerate ì„¤ì¹˜\n",
        "!pip install transformers[torch]\n",
        "!pip install accelerate>=0.20.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LV65OMc_wGrJ"
      },
      "source": [
        "modules ê³¼ packges import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JcHXA33leT0A"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, List, Union\n",
        "import torch\n",
        "\n",
        "# import the relavant libraries for loggin in\n",
        "from huggingface_hub import HfApi, HfFolder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTo-ygLdwTwp"
      },
      "source": [
        "# í•¨ìˆ˜ ì •ì˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TcErvqAgefKS"
      },
      "outputs": [],
      "source": [
        "def login_hugging_face(token):\n",
        "    \"\"\"\n",
        "    Hugging Face API í† í°ì„ ì‚¬ìš©í•˜ì—¬ Hugging Faceì— ë¡œê·¸ì¸í•©ë‹ˆë‹¤.\n",
        "    \"\"\"\n",
        "    folder = HfFolder()\n",
        "    folder.save_token(token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_jIKSBAtTEo"
      },
      "source": [
        "ëª¨ë¸ì— ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©ë  ë°ì´í„°ì™€ ë¼ë²¨ ë°ì´í„°ê°€ ì¤€ë¹„"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "povAUjkcejQU"
      },
      "outputs": [],
      "source": [
        "def prepare_dataset(batch):\n",
        "    \"\"\"\n",
        "    Whisper AI ëª¨ë¸ì— ì í•©í•œ í˜•ì‹ìœ¼ë¡œ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤.\n",
        "    \"\"\"\n",
        "    # ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ 48kHzì—ì„œ 16kHzë¡œ ë³€í™˜í•˜ì—¬ ë¡œë“œ\n",
        "    audio = batch[\"audio\"]\n",
        "\n",
        "    # ì…ë ¥ ì˜¤ë””ì˜¤ ë°°ì—´ë¡œë¶€í„° log-Mel ì…ë ¥ íŠ¹ì„±ì„ ê³„ì‚°\n",
        "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
        "\n",
        "    # ëŒ€ìƒ í…ìŠ¤íŠ¸ë¥¼ í† í°í™”í•˜ê³  ë¼ë²¨ IDë¡œ ì¸ì½”ë”©\n",
        "    batch[\"labels\"] = tokenizer(batch[\"sentence\"]).input_ids\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHs-HkuJtbXe"
      },
      "source": [
        "ë°ì´í„° ì½œë ˆì´í„° í´ë˜ìŠ¤ëŠ” ASR ëª¨ë¸ì˜ í›ˆë ¨ ë° í‰ê°€ ê³¼ì •ì—ì„œ ë°ì´í„°ì˜ ì „ì²˜ë¦¬ì™€ íŒ¨ë”©ì„ ì²˜ë¦¬í•˜ëŠ” ì—­í• ì„ ìˆ˜í–‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "aQEmML4Zex5z"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class DataCollatorSpeechSeq2SeqWithPadding:\n",
        "    \"\"\"\n",
        "    Use Data Collator to perform Speech Seq2Seq with padding\n",
        "    \"\"\"\n",
        "    processor: Any\n",
        "\n",
        "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
        "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
        "        # first treat the audio inputs by simply returning torch tensors\n",
        "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
        "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
        "\n",
        "        # get the tokenized label sequences\n",
        "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
        "        # pad the labels to max length\n",
        "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
        "\n",
        "        # replace padding with -100 to ignore loss correctly\n",
        "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
        "\n",
        "        # if bos token is appended in previous tokenization step,\n",
        "        # cut bos token here as it's append later anyways\n",
        "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
        "            labels = labels[:, 1:]\n",
        "\n",
        "        batch[\"labels\"] = labels\n",
        "\n",
        "        return batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_qwfaqUvf4w"
      },
      "source": [
        "í‰ê¸°ì§€í‘œ: CER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mg9QFaBGe2nj",
        "outputId": "87aa94ba-f408-4613-fe6d-c3180645bb71"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-8-c81d87c6f9c2>:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ğŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
            "  cer_metric = load_metric(\"cer\")\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_metric\n",
        "\n",
        "cer_metric = load_metric(\"cer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NebW2x_HiTEw"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(pred):\n",
        "    labels_ids = pred.label_ids\n",
        "    pred_ids = pred.predictions\n",
        "\n",
        "    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    labels_ids[labels_ids == -100] = processor.tokenizer.pad_token_id\n",
        "    label_str = processor.batch_decode(labels_ids, skip_special_tokens=True)\n",
        "\n",
        "    cer = cer_metric.compute(predictions=pred_str, references=label_str)\n",
        "\n",
        "    return {\"cer\": cer}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YT9LBBXdwIsi"
      },
      "source": [
        "# STEP 0. Hugging Face ë¡œê·¸ì¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywDnKqWTe5Hu",
        "outputId": "594358f0-de8a-4e41-bdcd-214d15efa58e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "We are logged in to Hugging Face now!\n"
          ]
        }
      ],
      "source": [
        "# get your account token from https://huggingface.co/settings/tokens\n",
        "token = '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'\n",
        "login_hugging_face(token)\n",
        "print('We are logged in to Hugging Face now!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qatnD5H2waD8"
      },
      "source": [
        "# STEP 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4wWS0DNhYVG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "def extract_zip_files(zip_file_path, extracted_folder_path):\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extracted_folder_path)\n",
        "\n",
        "def change_folder_structure(extracted_folder_path):\n",
        "    audio_target_dir = os.path.join(extracted_folder_path, \"audio\")\n",
        "    label_target_dir = os.path.join(extracted_folder_path, \"labels\")\n",
        "\n",
        "    # í´ë” ìƒì„±\n",
        "    os.makedirs(audio_target_dir, exist_ok=True)\n",
        "    os.makedirs(label_target_dir, exist_ok=True)\n",
        "\n",
        "    for root, _, files in os.walk(extracted_folder_path):\n",
        "        for file in files:\n",
        "            if file.endswith(\".wav\"):\n",
        "                audio_file_path = os.path.join(root, file)\n",
        "                new_audio_file_path = os.path.join(audio_target_dir, file)\n",
        "                shutil.move(audio_file_path, new_audio_file_path)\n",
        "\n",
        "            elif file.endswith(\".json\"):\n",
        "                label_file_path = os.path.join(root, file)\n",
        "                audio_id = file.split(\".\")[0]\n",
        "                new_label_file_path = os.path.join(label_target_dir, f\"{audio_id}.txt\")\n",
        "                shutil.move(label_file_path, new_label_file_path)\n",
        "\n",
        "    # ë¹ˆ í´ë” ì œê±° (ì˜¤ì§ audio_target_dirì™€ label_target_dirë§Œ ë‚¨ì•„ìˆì„ ê²ƒ)\n",
        "    for root, dirs, _ in os.walk(extracted_folder_path, topdown=False):\n",
        "        for dir in dirs:\n",
        "            if dir not in [os.path.basename(audio_target_dir), os.path.basename(label_target_dir)]:\n",
        "                dir_path = os.path.join(root, dir)\n",
        "                os.rmdir(dir_path)\n",
        "\n",
        "# 2. ë°ì´í„° íŒŒì¼ì´ ì €ì¥ëœ ê²½ë¡œë¥¼ ì§€ì •í•©ë‹ˆë‹¤.\n",
        "zip_file_path_audio = '/content/drive/MyDrive/data_file/sample_1500_ko_child/audio_sample.zip'\n",
        "zip_file_path_label = '/content/drive/MyDrive/data_file/sample_1500_ko_child/label_sample.zip'\n",
        "extracted_folder_path = '/content/data/'  # ì••ì¶• í•´ì œëœ ë°ì´í„°ê°€ ì €ì¥ë  í´ë” ê²½ë¡œ\n",
        "\n",
        "# í´ë” ì´ˆê¸°í™”\n",
        "if os.path.exists(extracted_folder_path):\n",
        "    shutil.rmtree(extracted_folder_path)\n",
        "\n",
        "# 3. zip íŒŒì¼ì„ ì••ì¶• í•´ì œí•©ë‹ˆë‹¤.\n",
        "extract_zip_files(zip_file_path_audio, extracted_folder_path)\n",
        "extract_zip_files(zip_file_path_label, extracted_folder_path)\n",
        "\n",
        "# 4. í´ë” êµ¬ì¡° ë³€ê²½\n",
        "change_folder_structure(extracted_folder_path)\n",
        "\n",
        "# 5. êµ¬ì¡° í™•ì¸\n",
        "# ë°ì´í„° í´ë” ê²½ë¡œ ì„¤ì •\n",
        "data_folder = '/content/data/'\n",
        "\n",
        "# audio í´ë” ë‚´ íŒŒì¼ ëª©ë¡ í™•ì¸\n",
        "audio_files = os.listdir(os.path.join(data_folder, 'audio'))\n",
        "print(\"Audio Files:\")\n",
        "print(audio_files)\n",
        "\n",
        "# labels í´ë” ë‚´ íŒŒì¼ ëª©ë¡ í™•ì¸\n",
        "label_files = os.listdir(os.path.join(data_folder, 'labels'))\n",
        "print(\"\\nLabel Files:\")\n",
        "print(label_files)\n",
        "\n",
        "# ì´ì œ \"/content/data/\" í´ë” ë‚´ì— \"audio\" í´ë”ì™€ \"labels\" í´ë”ê°€ ìƒì„±ë˜ë©°,\n",
        "# í•´ë‹¹ í´ë”ì— ì›ì²œë°ì´í„°ì¸ wav íŒŒì¼ê³¼ ë¼ë²¨ë§ë°ì´í„°ì¸ txt íŒŒì¼ì´ ì €ì¥ë©ë‹ˆë‹¤.\n",
        "# ì´í›„ì—ëŠ” í•´ë‹¹ ê²½ë¡œì—ì„œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™€ì„œ í•™ìŠµì„ ì§„í–‰í•˜ì‹œë©´ ë©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7WR1Atowdo5"
      },
      "source": [
        "audio data ê°œìˆ˜ì™€ label data ê°œìˆ˜ ê°™ì€ì§€ í™•ì¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jVpPltDlYAL",
        "outputId": "a938e411-12c9-4695-a7f3-6c040cbe1923"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ì˜¤ë””ì˜¤ íŒŒì¼ ê°œìˆ˜: 1589\n",
            "JSON íŒŒì¼ ê°œìˆ˜: 1589\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "data_folder = \"/content/data\"\n",
        "audio_folder = os.path.join(data_folder, \"audio\")\n",
        "label_folder = os.path.join(data_folder, \"labels\")\n",
        "\n",
        "# audio í´ë” ë‚´ì˜ íŒŒì¼ ê°œìˆ˜ í™•ì¸\n",
        "audio_files = [file for file in os.listdir(audio_folder) if file.endswith(\".wav\")]\n",
        "print(f\"ì˜¤ë””ì˜¤ íŒŒì¼ ê°œìˆ˜: {len(audio_files)}\")\n",
        "\n",
        "# labels í´ë” ë‚´ì˜ íŒŒì¼ ê°œìˆ˜ í™•ì¸\n",
        "label_files = [file for file in os.listdir(label_folder) if file.endswith(\".txt\")]\n",
        "print(f\"JSON íŒŒì¼ ê°œìˆ˜: {len(label_files)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNbgGyYjwm6P"
      },
      "source": [
        "trainê³¼ test ë°ì´í„°ë¡œ ë‚˜ëˆ„ê¸° ë° ëª¨ë¸ í•™ìŠµì„ ìœ„í•œ êµ¬ì¡° ë³€ê²½"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "GAcfOesukZ1W"
      },
      "outputs": [],
      "source": [
        "from datasets import DatasetDict, Dataset, load_dataset\n",
        "import os\n",
        "import random\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNqAcayci4BN",
        "outputId": "8cac6994-7e75-4492-81a1-3220f8f0392a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['audio', 'sentence'],\n",
            "        num_rows: 1430\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['audio', 'sentence'],\n",
            "        num_rows: 159\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "def create_dataset(data_folder):\n",
        "    audio_folder = os.path.join(data_folder, \"audio\")\n",
        "    label_folder = os.path.join(data_folder, \"labels\")\n",
        "\n",
        "    # audio í´ë” ë‚´ì˜ WAV íŒŒì¼ ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜´\n",
        "    audio_files = [file for file in os.listdir(audio_folder) if file.endswith(\".wav\")]\n",
        "\n",
        "    # ë°ì´í„°ì…‹ ìƒì„±\n",
        "    dataset_dict = DatasetDict()\n",
        "    dataset = {\"audio\": [], \"sentence\": []}\n",
        "\n",
        "    # ë¼ë²¨ íŒŒì¼ì˜ \"FileName\"ì„ ê¸°ì¤€ìœ¼ë¡œ ì˜¤ë””ì˜¤ íŒŒì¼ ì°¾ì•„ì„œ ì—°ê²°\n",
        "    for label_file in os.listdir(label_folder):\n",
        "        label_path = os.path.join(label_folder, label_file)\n",
        "\n",
        "        with open(label_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            label_data = json.load(f)\n",
        "            audio_filename = label_data[\"File\"][\"FileName\"]\n",
        "            sentence = label_data[\"Transcription\"][\"LabelText\"]\n",
        "\n",
        "            # \"FileName\"ê³¼ ì¼ì¹˜í•˜ëŠ” ì˜¤ë””ì˜¤ íŒŒì¼ ì°¾ì•„ì„œ ì—°ê²°\n",
        "            matching_audio = [audio_file for audio_file in audio_files if audio_filename in audio_file]\n",
        "            if matching_audio:\n",
        "                audio_path = os.path.join(audio_folder, matching_audio[0])\n",
        "                dataset[\"audio\"].append(audio_path)\n",
        "                dataset[\"sentence\"].append(sentence)\n",
        "\n",
        "    # ë°ì´í„°ë¥¼ ë¬´ì‘ìœ„ë¡œ ì„ì–´ì„œ trainê³¼ testë¡œ ë‚˜ëˆ„ê¸°\n",
        "    data_size = len(dataset[\"audio\"])\n",
        "    random_indices = list(range(data_size))\n",
        "    random.shuffle(random_indices)\n",
        "    train_size = int(data_size * 0.9)\n",
        "\n",
        "    train_data = {\"audio\": [], \"sentence\": []}\n",
        "    test_data = {\"audio\": [], \"sentence\": []}\n",
        "\n",
        "    for i in random_indices[:train_size]:\n",
        "        train_data[\"audio\"].append(dataset[\"audio\"][i])\n",
        "        train_data[\"sentence\"].append(dataset[\"sentence\"][i])\n",
        "\n",
        "    for i in random_indices[train_size:]:\n",
        "        test_data[\"audio\"].append(dataset[\"audio\"][i])\n",
        "        test_data[\"sentence\"].append(dataset[\"sentence\"][i])\n",
        "\n",
        "    # ë°ì´í„°ì…‹ì— ì¶”ê°€\n",
        "    dataset_dict[\"train\"] = Dataset.from_dict(train_data)\n",
        "    dataset_dict[\"test\"] = Dataset.from_dict(test_data)\n",
        "\n",
        "    return dataset_dict\n",
        "\n",
        "# ë°ì´í„° í´ë” ê²½ë¡œ ì§€ì •\n",
        "data_folder = \"/content/data\"\n",
        "\n",
        "# ë°ì´í„°ì…‹ ìƒì„±\n",
        "custom_dataset = create_dataset(data_folder)\n",
        "\n",
        "# \"sentence\" í•„ë“œë§Œ ì¶œë ¥\n",
        "print(custom_dataset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bphs7qjGwqov"
      },
      "source": [
        "audio data ì™€ text data ì¼ë¶€ ì¶œë ¥"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5YEK2-Yl2jr",
        "outputId": "1d8cbcd5-6dce-40f1-fdf3-b25cd9384f61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ì˜¤ë””ì˜¤ ë°ì´í„° ì¼ë¶€ ì¶œë ¥:\n",
            "/content/data/audio/K000108853-BMG30-L1N2D4-E-K0KK-04692197.wav\n",
            "\n",
            "í…ìŠ¤íŠ¸ ë¬¸ì¥ ë°ì´í„° ì¼ë¶€ ì¶œë ¥:\n",
            "ë‚˜ëŠ” ì–Œì „í•œì²™ êµ´ì—ˆë‹¤.\n"
          ]
        }
      ],
      "source": [
        "# ì˜¤ë””ì˜¤ ë°ì´í„° ì¼ë¶€ ì¶œë ¥\n",
        "print(\"ì˜¤ë””ì˜¤ ë°ì´í„° ì¼ë¶€ ì¶œë ¥:\")\n",
        "print(custom_dataset[\"train\"][\"audio\"][2])\n",
        "print()\n",
        "\n",
        "# í…ìŠ¤íŠ¸ ë¬¸ì¥ ë°ì´í„° ì¼ë¶€ ì¶œë ¥\n",
        "print(\"í…ìŠ¤íŠ¸ ë¬¸ì¥ ë°ì´í„° ì¼ë¶€ ì¶œë ¥:\")\n",
        "print(custom_dataset[\"train\"][\"sentence\"][2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYXaMpOtw6Lm"
      },
      "source": [
        "# STEP 2. Feature Extractor, Tokenizer and Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "6ljILt1DpwcJ"
      },
      "outputs": [],
      "source": [
        "from transformers import WhisperFeatureExtractor\n",
        "from transformers import WhisperTokenizer\n",
        "\n",
        "# - Load Feature extractor: WhisperFeatureExtractor\n",
        "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-base\")\n",
        "\n",
        "# - Load Tokenizer: WhisperTokenizer\n",
        "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-base\", language=\"korean\", task=\"transcribe\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRlUZ0PmxAEL"
      },
      "source": [
        "# STEP 3. Combine elements with WhisperProcessor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "clpQzKlqpzq3"
      },
      "outputs": [],
      "source": [
        "from transformers import WhisperProcessor\n",
        "processor = WhisperProcessor.from_pretrained(\"openai/whisper-base\", language=\"korean\", task=\"transcribe\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzx2yMdDxVJv"
      },
      "source": [
        "# STEP 4. ë°ì´í„° ì¤€ë¹„"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210,
          "referenced_widgets": [
            "2263434a834c469eb90251b8a800efad",
            "0e2caf292c504e109c1cb3e5cd940893",
            "90604027b3a445a29edbf9cdcef5d759",
            "d848b23b93fe4f91be8a7596043d8e47",
            "e93bcd5185ed4d9aabec2d32b8bf81d3",
            "6ea530df1d6243db970f7f969daba51a",
            "3342dc2411de4d5b8c7b261906160798",
            "82b860a16d004a74a45ba7b9f0fb9ad4",
            "738f408cf65c4df79fa59d97511ceb85",
            "867bc9bc021440219bbe443f0a41c291",
            "679f707cf8c74119b5134b47c8531ecc",
            "bfe2263ecc13434baddccbe5fd7d9d65",
            "197ed8b627bf4241b451f2beeb97dd56",
            "2a9d7b3358304ae6ad690f5996ddfbf2",
            "9bf5308f43174d98b6fdd8fe07024d13",
            "8c71b42ecc5f4924ae6b60b9790d75f9",
            "d498ec31f39a48fb8d0e78cd16d20872",
            "aa7c5ca0f736482ebc223ea895f57ce5",
            "00aae41789be42189b934e7a63bd1a2b",
            "38fd199c48934935b248e05f78e65d9b",
            "afa4a5a434424858a69e731feb37b387",
            "3efc8c71dac0488383c38b2d2c6270d6"
          ]
        },
        "id": "luZjHLr2p2PU",
        "outputId": "1a9437eb-fcf1-4a4b-a79d-0313b2061f25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| Check the audio example\n",
            "{'audio': '/content/data/audio/K000108426-BFG30-L1N2D1-E-K0KK-04694419.wav', 'sentence': 'ë§Œë“¤ë©´ì„œ ìë‘ë„ í•˜ê³  ì˜ˆì˜ê²Œ ë§Œë“¤ì—ˆë‹¤ê±°ë‚˜ ì˜ ì–´ìš¸ë¦¬ëŠ” ìƒ‰ì„ ì˜ ì°¾ì•˜ë‹¤ëŠ” ë“± ì¹­ì°¬ì„ ë“£ëŠ” ê²ƒë„ ê¸°ë¶„ì´ ì¢‹ì•˜ë‹¤.'}\n",
            "\n",
            "| Check the effect of downsampling:\n",
            "{'audio': {'path': '/content/data/audio/K000108426-BFG30-L1N2D1-E-K0KK-04694419.wav', 'array': array([0., 0., 0., ..., 0., 0., 0.]), 'sampling_rate': 16000}, 'sentence': 'ë§Œë“¤ë©´ì„œ ìë‘ë„ í•˜ê³  ì˜ˆì˜ê²Œ ë§Œë“¤ì—ˆë‹¤ê±°ë‚˜ ì˜ ì–´ìš¸ë¦¬ëŠ” ìƒ‰ì„ ì˜ ì°¾ì•˜ë‹¤ëŠ” ë“± ì¹­ì°¬ì„ ë“£ëŠ” ê²ƒë„ ê¸°ë¶„ì´ ì¢‹ì•˜ë‹¤.'}\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2263434a834c469eb90251b8a800efad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=8):   0%|          | 0/1430 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bfe2263ecc13434baddccbe5fd7d9d65",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=8):   0%|          | 0/159 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print('| Check the audio example')\n",
        "print(f'{custom_dataset[\"train\"][0]}\\n')\n",
        "\n",
        "# Downsample from 48kHZ to 16kHZ\n",
        "# Whisper AI ëª¨ë¸ì´ 16kHzì˜ ìƒ˜í”Œë§ ì†ë„ì—ì„œ í›ˆë ¨ë˜ì–´ì„œ\n",
        "# ì…ë ¥ ë°ì´í„°ë¥¼ 16kHzë¡œ ë‹¤ìš´ìƒ˜í”Œë§í•˜ëŠ” ê²ƒì´ í•„ìš”\n",
        "from datasets import Audio\n",
        "custom_dataset = custom_dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
        "\n",
        "print('| Check the effect of downsampling:')\n",
        "print(f'{custom_dataset[\"train\"][0]}\\n')\n",
        "\n",
        "# Prepare and use function to prepare our data ready for the Whisper AI model\n",
        "custom_dataset = custom_dataset.map(\n",
        "    prepare_dataset,\n",
        "    remove_columns=custom_dataset.column_names[\"train\"],\n",
        "    num_proc=8 # num_proc > 1 will enable multiprocessing / num_proc = 2 -> 8ë¡œ ë³€ê²½í•¨\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRFES7w9xava"
      },
      "source": [
        "# STEP 5. Training and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ceB98ofDqR2u"
      },
      "outputs": [],
      "source": [
        "# STEP 5.1. Initialize the Data collator\n",
        "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n",
        "\n",
        "# STEP 5.1. Define evaluation metric\n",
        "import evaluate\n",
        "metric = evaluate.load(\"cer\")\n",
        "\n",
        "# STEP 5.3. Load a pre-trained Checkpoint\n",
        "from transformers import WhisperForConditionalGeneration\n",
        "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-base\")\n",
        "\n",
        "\"\"\"\n",
        "Overide generation arguments:\n",
        "- no tokens are forced as decoder outputs: https://huggingface.co/docs/transformers/main_classes/text_generation#transformers.generation_utils.GenerationMixin.generate.forced_decoder_ids\n",
        "- no tokens are suppressed during generation: https://huggingface.co/docs/transformers/main_classes/text_generation#transformers.generation_utils.GenerationMixin.generate.suppress_tokens\n",
        "\"\"\"\n",
        "model.config.forced_decoder_ids = None\n",
        "model.config.suppress_tokens = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "9gGTa9HVqXov",
        "outputId": "c317aa0e-73a4-4a92-df61-e3f48b2926f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training ì‹œì‘\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache = True` is incompatible with gradient checkpointing. Setting `use_cache = False`...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [200/200 21:26, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.734400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.927400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training ì™„ë£Œ\n"
          ]
        }
      ],
      "source": [
        "# STEP 5.4. Define the training configuration\n",
        "\"\"\"\n",
        "Check for Seq2SeqTrainingArguments here:\n",
        "https://huggingface.co/docs/transformers/main_classes/trainer#transformers.Seq2SeqTrainingArguments\n",
        "\"\"\"\n",
        "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./whisper-base-0813\",  # ì €ì¥ëœ ëª¨ë¸ ë° ê²°ê³¼ë¬¼ì˜ ë””ë ‰í† ë¦¬ ê²½ë¡œ\n",
        "    per_device_train_batch_size=16,  # í•œ ë²ˆì— ì²˜ë¦¬ë˜ëŠ” í›ˆë ¨ ë°°ì¹˜ í¬ê¸°\n",
        "    gradient_accumulation_steps=2,  # ë°°ì¹˜ í¬ê¸° ê°ì†Œì‹œ ê·¸ë˜ë””ì–¸íŠ¸ ëˆ„ì ì„ í†µí•œ í•™ìŠµ ì•ˆì •í™”\n",
        "    learning_rate=2e-6,  # í•™ìŠµë¥ \n",
        "    warmup_steps=20,  # ì´ˆê¸° í•™ìŠµë¥  ì¡°ì •ì„ ìœ„í•œ ì›œì—… ìŠ¤í… ìˆ˜ / ì¼ë°˜ì ìœ¼ë¡œëŠ” 10% ~ 20%ì˜ ì „ì²´ í•™ìŠµ ìŠ¤í… ìˆ˜ì— í•´ë‹¹í•˜ëŠ” ê°’ì„ ì‹œë„\n",
        "    max_steps=200,  # ì „ì²´ í›ˆë ¨ ìŠ¤í… ìˆ˜\n",
        "    gradient_checkpointing=True,  # ê·¸ë˜ë””ì–¸íŠ¸ ì²´í¬í¬ì¸íŒ…ì„ í†µí•œ ë©”ëª¨ë¦¬ ì ˆì•½\n",
        "    fp16=True,  # FP16 í˜•ì‹ìœ¼ë¡œ í›ˆë ¨ ìˆ˜í–‰ (ë°˜ì •ë°€ë„ ë¶€ë™ì†Œìˆ˜ì )( cpu ê°€ë™ì‹œ ì•ˆì”€)\n",
        "    evaluation_strategy=\"no\",  # ê²€ì¦ ìˆ˜í–‰ ì „ëµ ì„¤ì • (\"step\"->\"no\")\n",
        "    per_device_eval_batch_size=8,  # í•œ ë²ˆì— ì²˜ë¦¬ë˜ëŠ” ê²€ì¦ ë°°ì¹˜ í¬ê¸°\n",
        "    predict_with_generate=True,  # ìƒì„±ëœ í† í°ì„ í†µí•´ ì˜ˆì¸¡ ìˆ˜í–‰\n",
        "    generation_max_length=225,  # ìƒì„±ëœ í† í°ì˜ ìµœëŒ€ ê¸¸ì´ (225 )\n",
        "    eval_steps=100,  # ê²€ì¦ ìˆ˜í–‰ ìŠ¤í… ìˆ˜\n",
        "    logging_steps=100,  # ë¡œê·¸ ê¸°ë¡ ìŠ¤í… ìˆ˜\n",
        "    load_best_model_at_end=False,  # í›ˆë ¨ ì¢…ë£Œ ì‹œ ìµœì  ëª¨ë¸ ë¡œë“œ ì—¬ë¶€\n",
        "    metric_for_best_model=\"cer\",  # ìµœì  ëª¨ë¸ ì„ ì •ì„ ìœ„í•œ í‰ê°€ ì§€í‘œ wer -> cerë¡œ ë³€ê²½\n",
        "    greater_is_better=False,  # í‰ê°€ ì§€í‘œ ê°’ì´ ë†’ì„ìˆ˜ë¡ ì¢‹ì€ì§€ ì—¬ë¶€\n",
        "    save_steps=100\n",
        ")\n",
        "\n",
        "# Initialize a trainer.\n",
        "\"\"\"\n",
        "Hugging Face trainerì— ë‹¤ìŒì˜ ê°’ì„ ì „ë‹¬\n",
        "training arguments, model, dataset, data collator and compute_metrics function.\n",
        "\"\"\"\n",
        "# ì§€ì •ëœ ì¸ì ë° êµ¬ì„±ìš”ì†Œë¡œ Initialize a trainer.\n",
        "trainer = Seq2SeqTrainer(\n",
        "    args=training_args,                   # ì´ì „ì— ì •ì˜í•œ í›ˆë ¨ ì¸ì\n",
        "    model=model,                          # í›ˆë ¨í•  ASR ëª¨ë¸\n",
        "    train_dataset=custom_dataset[\"train\"],# í›ˆë ¨ ë°ì´í„°ì…‹\n",
        "    eval_dataset=custom_dataset[\"test\"],  # í‰ê°€ ë°ì´í„°ì…‹\n",
        "    data_collator=data_collator,           # ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ìœ„í•œ ë°ì´í„° ì½œë ˆì´í„°\n",
        "    compute_metrics=compute_metrics,          # CER ë©”íŠ¸ë¦­ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜\n",
        "    tokenizer=feature_extractor, # ì…ë ¥ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ í† í¬ë‚˜ì´ì €\n",
        ")\n",
        "\n",
        "# training ì‹œì‘ì „ì— processor object ì €ì¥\n",
        "processor.save_pretrained(training_args.output_dir)\n",
        "\n",
        "# STEP 5.5. Training\n",
        "\"\"\"\n",
        "Training will take appr. 5-10 hours depending on your GPU.\n",
        "\"\"\"\n",
        "print('Training ì‹œì‘')\n",
        "trainer.train()  # <-- training ì‹œì‘\n",
        "print('Training ì™„ë£Œ')\n",
        "\n",
        "#\"Step\": ëª¨ë¸ì˜ í›ˆë ¨ ê³¼ì •ì—ì„œ ì§„í–‰ë˜ëŠ” ê° ìŠ¤í…ì„ ë‚˜íƒ€ë‚´ëŠ” ìˆ«ìì…ë‹ˆë‹¤.\n",
        "#ìŠ¤í…ì€ ì£¼ë¡œ ë°°ì¹˜(batch) ë‹¨ìœ„ë¡œ ëª¨ë¸ì´ ì—…ë°ì´íŠ¸ë˜ëŠ” ì§€ì ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
        "\n",
        "# \"Training Loss\": í›ˆë ¨ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµí•  ë•Œ ë‚˜íƒ€ë‚˜ëŠ” ì†ì‹¤ ê°’ì…ë‹ˆë‹¤.\n",
        "#ì´ ê°’ì€ ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ê²°ê³¼ì™€ ì‹¤ì œ ì •ë‹µê³¼ì˜ ì°¨ì´ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n",
        "\n",
        "# \"Validation Loss\": í›ˆë ¨ ì¤‘ì— ì¼ì • ì£¼ê¸°ë§ˆë‹¤ ê²€ì¦ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ ì„±ëŠ¥ì„\n",
        "# í‰ê°€í•œ í›„ ë‚˜íƒ€ë‚˜ëŠ” ì†ì‹¤ ê°’ì…ë‹ˆë‹¤.\n",
        "# ì´ ê°’ë„ ë§ˆì°¬ê°€ì§€ë¡œ ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ì™€ ì‹¤ì œ ì •ë‹µê³¼ì˜ ì°¨ì´ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n",
        "# ê²€ì¦ ì†ì‹¤ì´ ê°ì†Œí•˜ëŠ” ê²ƒì€ ëª¨ë¸ì´ ì¼ë°˜í™”ë˜ëŠ” í‘œì‹œì…ë‹ˆë‹¤.\n",
        "\n",
        "# \"CER\" (Character Error Rate): í›ˆë ¨ ì¤‘ì— ì¼ì • ì£¼ê¸°ë§ˆë‹¤ ê²€ì¦ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬\n",
        "#ëª¨ë¸ì˜ ë¬¸ì ì—ëŸ¬ ë¹„ìœ¨(CER)ì„ í‰ê°€í•œ ê°’ì…ë‹ˆë‹¤.\n",
        "#CERì€ í…ìŠ¤íŠ¸ ë¶„ì•¼ì—ì„œ ìì£¼ ì‚¬ìš©ë˜ëŠ” í‰ê°€ ì§€í‘œ ì¤‘ í•˜ë‚˜ë¡œ,\n",
        "#ëª¨ë¸ì´ ìƒì„±í•œ í…ìŠ¤íŠ¸ì™€ ì‹¤ì œ í…ìŠ¤íŠ¸ ì‚¬ì´ì˜ ë¬¸ì ìˆ˜ì¤€ ì˜¤ë¥˜ ë¹„ìœ¨ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n",
        "#CERì´ ë‚®ì„ìˆ˜ë¡ ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ì¢‹ë‹¤ê³  íŒë‹¨ë©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ic1yCT8HuUI8"
      },
      "source": [
        "í•™ìŠµëœ ëª¨ë¸ í‰ê°€"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "GPMYJbdee4QU"
      },
      "outputs": [],
      "source": [
        "# trainer.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGxBKiX1EQVC"
      },
      "source": [
        "í•™ìŠµëœ ëª¨ë¸ ì €ì¥"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "liHO1-IIEP4O"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(\"/content/drive/MyDrive/model/whisper_base_0813_ver1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mufs_hbwIias",
        "outputId": "29d66d7d-9a5b-413b-fcce-acbc75738c06"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/model/whisper_base_0813_ver1/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/model/whisper_base_0813_ver1/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/model/whisper_base_0813_ver1/vocab.json',\n",
              " '/content/drive/MyDrive/model/whisper_base_0813_ver1/merges.txt',\n",
              " '/content/drive/MyDrive/model/whisper_base_0813_ver1/normalizer.json',\n",
              " '/content/drive/MyDrive/model/whisper_base_0813_ver1/added_tokens.json',\n",
              " '/content/drive/MyDrive/model/whisper_base_0813_ver1/tokenizer.json')"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Load the trained tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/whisper-base-0813\")\n",
        "\n",
        "# Specify the directory where you want to save the tokenizer\n",
        "save_directory = \"/content/drive/MyDrive/model/whisper_base_0813_ver1\"\n",
        "\n",
        "# Save the tokenizer to the specified directory\n",
        "tokenizer.save_pretrained(save_directory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4Ucc7_ZuaHa"
      },
      "source": [
        "ëª¨ë¸ íŒŒì¼ë‚´ìš© í™•ì¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTNvGXJ4uamH",
        "outputId": "ec088954-75d4-4a4f-98b4-b9f12eff5eb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['config.json', 'generation_config.json', 'pytorch_model.bin', 'preprocessor_config.json', 'training_args.bin', 'tokenizer_config.json', 'special_tokens_map.json', 'added_tokens.json', 'vocab.json', 'merges.txt', 'normalizer.json', 'tokenizer.json']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "model_path = \"/content/drive/MyDrive/model/whisper_base_0813_ver1\"\n",
        "files_in_model_path = os.listdir(model_path)\n",
        "print(files_in_model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAvxlHpuDdGP"
      },
      "source": [
        "# STEP 6. Model use"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtMD0NWiucha"
      },
      "source": [
        "ëª¨ë¸ ì‹¤í–‰ì½”ë“œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GtKF4UOueAc",
        "outputId": "d4cbd753-8ffb-4aae-f6a9-62a3b2a6db48"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1254: UserWarning: Using the model-agnostic default `max_length` (=448) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " í…€ë²ˆì§¸ ë¶™ì€ íŒ€ì€ ì „ê°ˆ íŒ€ì´ ì—†ë‹¤.\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1254: UserWarning: Using the model-agnostic default `max_length` (=448) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ì¹œêµ¬ë“¤ê³¼ ê°™ì´ ê°€ì„œ ë„ˆë¬´ ì„¤ë ˆë‹¤\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1254: UserWarning: Using the model-agnostic default `max_length` (=448) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ë©”ë¯¸ê°€ ì¤‘ì€ 7ë…„ ë™ì•ˆ ë‹¹ì— ìˆë‹¤ê°€ ë‚˜ì˜¨ ê±°ë¼ê³  ì•ˆ í–ˆë‹¤.\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "model_name_or_path = \"/content/drive/MyDrive/model/whisper_base_0813_ver1\"\n",
        "asr = pipeline(model=model_name_or_path, task=\"automatic-speech-recognition\")\n",
        "\n",
        "def transcribe_audio(audio_path):\n",
        "    transcription = asr(audio_path)\n",
        "    return transcription['text']\n",
        "\n",
        "audio_file_paths = [\n",
        "    \"/content/drive/MyDrive/data_file/á„á…¦á„‰á…³á„á…³ á„‹á…³á†·á„‹á…¯á†«/K00013596-BMG23-L1N2D1-E-K0KK-02164576.wav\",\n",
        "    \"/content/drive/MyDrive/data_file/á„á…¦á„‰á…³á„á…³ á„‹á…³á†·á„‹á…¯á†«/K00013596-BMG23-L1N2D1-E-K0KK-02164794.wav\",\n",
        "    \"/content/drive/MyDrive/data_file/á„á…¦á„‰á…³á„á…³ á„‹á…³á†·á„‹á…¯á†«/K00013596-BMG23-L1N2D1-E-K0KK-02165323.wav\"\n",
        "    # ì¶”ê°€ ìŒì„± íŒŒì¼ ê²½ë¡œ\n",
        "]\n",
        "\n",
        "for audio_file_path in audio_file_paths:\n",
        "    transcription_text = transcribe_audio(audio_file_path)\n",
        "    print(transcription_text)\n",
        "    print(\"=\" * 50)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "e90zKmPewaL2"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00aae41789be42189b934e7a63bd1a2b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e2caf292c504e109c1cb3e5cd940893": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ea530df1d6243db970f7f969daba51a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3342dc2411de4d5b8c7b261906160798",
            "value": "Map (num_proc=8): 100%"
          }
        },
        "197ed8b627bf4241b451f2beeb97dd56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d498ec31f39a48fb8d0e78cd16d20872",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_aa7c5ca0f736482ebc223ea895f57ce5",
            "value": "Map (num_proc=8): 100%"
          }
        },
        "2263434a834c469eb90251b8a800efad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e2caf292c504e109c1cb3e5cd940893",
              "IPY_MODEL_90604027b3a445a29edbf9cdcef5d759",
              "IPY_MODEL_d848b23b93fe4f91be8a7596043d8e47"
            ],
            "layout": "IPY_MODEL_e93bcd5185ed4d9aabec2d32b8bf81d3"
          }
        },
        "2a9d7b3358304ae6ad690f5996ddfbf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00aae41789be42189b934e7a63bd1a2b",
            "max": 159,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_38fd199c48934935b248e05f78e65d9b",
            "value": 159
          }
        },
        "3342dc2411de4d5b8c7b261906160798": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38fd199c48934935b248e05f78e65d9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3efc8c71dac0488383c38b2d2c6270d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "679f707cf8c74119b5134b47c8531ecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ea530df1d6243db970f7f969daba51a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "738f408cf65c4df79fa59d97511ceb85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "82b860a16d004a74a45ba7b9f0fb9ad4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "867bc9bc021440219bbe443f0a41c291": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c71b42ecc5f4924ae6b60b9790d75f9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90604027b3a445a29edbf9cdcef5d759": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82b860a16d004a74a45ba7b9f0fb9ad4",
            "max": 1430,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_738f408cf65c4df79fa59d97511ceb85",
            "value": 1430
          }
        },
        "9bf5308f43174d98b6fdd8fe07024d13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afa4a5a434424858a69e731feb37b387",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3efc8c71dac0488383c38b2d2c6270d6",
            "value": " 159/159 [00:29&lt;00:00,  4.78 examples/s]"
          }
        },
        "aa7c5ca0f736482ebc223ea895f57ce5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afa4a5a434424858a69e731feb37b387": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfe2263ecc13434baddccbe5fd7d9d65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_197ed8b627bf4241b451f2beeb97dd56",
              "IPY_MODEL_2a9d7b3358304ae6ad690f5996ddfbf2",
              "IPY_MODEL_9bf5308f43174d98b6fdd8fe07024d13"
            ],
            "layout": "IPY_MODEL_8c71b42ecc5f4924ae6b60b9790d75f9"
          }
        },
        "d498ec31f39a48fb8d0e78cd16d20872": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d848b23b93fe4f91be8a7596043d8e47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_867bc9bc021440219bbe443f0a41c291",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_679f707cf8c74119b5134b47c8531ecc",
            "value": " 1430/1430 [02:28&lt;00:00,  8.82 examples/s]"
          }
        },
        "e93bcd5185ed4d9aabec2d32b8bf81d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
